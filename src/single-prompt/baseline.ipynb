{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrV21bF8yUQL",
        "outputId": "106a92ae-29d2-4bbe-e574-0b3342391447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Google ColaboratoryÁí∞Â¢É„ÇíÊ§úÂá∫„Åó„Åæ„Åó„Åü\n",
            "\n",
            "üì¶ ÂøÖË¶Å„Å™„É©„Ç§„Éñ„É©„É™„Çí„Ç§„É≥„Çπ„Éà„Éº„É´‰∏≠...\n",
            "‚úÖ „É©„Ç§„Éñ„É©„É™„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´ÂÆå‰∫Ü\n",
            "\n",
            "üì• „É™„Éù„Ç∏„Éà„É™„Çí„ÇØ„É≠„Éº„É≥‰∏≠: https://github.com/lasa-or-jp/la-bench.git\n",
            "‚úÖ „É™„Éù„Ç∏„Éà„É™„ÅÆ„ÇØ„É≠„Éº„É≥ÂÆå‰∫Ü: la-bench/\n",
            "\n",
            "üìç ‰ΩúÊ•≠„Éá„Ç£„É¨„ÇØ„Éà„É™: /content/la-bench\n",
            "\n",
            "üìä „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÊßãÈÄ†:\n",
            "total 420\n",
            "drwxr-xr-x 9 root root   4096 Nov 18 05:37 .\n",
            "drwxr-xr-x 1 root root   4096 Nov 18 05:37 ..\n",
            "drwxr-xr-x 2 root root   4096 Nov 18 05:37 announcements\n",
            "-rw-r--r-- 1 root root   4741 Nov 18 05:37 CLAUDE.md\n",
            "drwxr-xr-x 4 root root   4096 Nov 18 05:37 code\n",
            "-rw-r--r-- 1 root root   2658 Nov 18 05:37 CONTRIBUTING.md\n",
            "drwxr-xr-x 5 root root   4096 Nov 18 05:37 data\n",
            "drwxr-xr-x 3 root root   4096 Nov 18 05:37 docs\n",
            "drwxr-xr-x 8 root root   4096 Nov 18 05:37 .git\n",
            "drwxr-xr-x 3 root root   4096 Nov 18 05:37 .github\n",
            "-rw-r--r-- 1 root root   1086 Nov 18 05:37 .gitignore\n",
            "-rw-r--r-- 1 root root   1101 Nov 18 05:37 LICENSE\n",
            "drwxr-xr-x 2 root root   4096 Nov 18 05:37 notebooks\n",
            "-rw-r--r-- 1 root root    569 Nov 18 05:37 pyproject.toml\n",
            "-rw-r--r-- 1 root root  13396 Nov 18 05:37 README.md\n",
            "-rw-r--r-- 1 root root    121 Nov 18 05:37 requirements.txt\n",
            "-rw-r--r-- 1 root root 346546 Nov 18 05:37 uv.lock\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Áí∞Â¢ÉË®≠ÂÆö„Å®„Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó\n",
        "\"\"\"\n",
        "LA-Bench 2025: ÂÆüÈ®ìÊâãÈ†ÜÁîüÊàê„Çø„Çπ„ÇØ\n",
        "Baseline Implementation for Google Colaboratory\n",
        "GitHub: https://github.com/lasa-or-jp/la-bench.git\n",
        "\"\"\"\n",
        "\n",
        "#@title 1. Áí∞Â¢É„Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó { display-mode: \"form\" }\n",
        "#@markdown „Åì„ÅÆ„Çª„É´„ÇíÂÆüË°å„Åó„Å¶ÂøÖË¶Å„Å™„É©„Ç§„Éñ„É©„É™„Çí„Ç§„É≥„Çπ„Éà„Éº„É´„Åó„ÄÅ„É™„Éù„Ç∏„Éà„É™„Çí„ÇØ„É≠„Éº„É≥„Åó„Åæ„Åô„ÄÇ\n",
        "\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Colab„Åã„Å©„ÅÜ„Åã„ÅÆÁ¢∫Ë™ç\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"‚úÖ Google ColaboratoryÁí∞Â¢É„ÇíÊ§úÂá∫„Åó„Åæ„Åó„Åü\")\n",
        "    # ÂøÖË¶Å„Å™„É©„Ç§„Éñ„É©„É™„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´\n",
        "    print(\"\\nüì¶ ÂøÖË¶Å„Å™„É©„Ç§„Éñ„É©„É™„Çí„Ç§„É≥„Çπ„Éà„Éº„É´‰∏≠...\")\n",
        "    !pip install -q openai pyyaml tqdm pandas\n",
        "\n",
        "    print(\"‚úÖ „É©„Ç§„Éñ„É©„É™„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´ÂÆå‰∫Ü\")\n",
        "\n",
        "    # GitHub„É™„Éù„Ç∏„Éà„É™„ÅÆ„ÇØ„É≠„Éº„É≥\n",
        "    REPO_URL = \"https://github.com/lasa-or-jp/la-bench.git\"\n",
        "    REPO_NAME = \"la-bench\"\n",
        "\n",
        "    if not os.path.exists(REPO_NAME):\n",
        "        print(f\"\\nüì• „É™„Éù„Ç∏„Éà„É™„Çí„ÇØ„É≠„Éº„É≥‰∏≠: {REPO_URL}\")\n",
        "        !git clone -q {REPO_URL}\n",
        "        print(f\"‚úÖ „É™„Éù„Ç∏„Éà„É™„ÅÆ„ÇØ„É≠„Éº„É≥ÂÆå‰∫Ü: {REPO_NAME}/\")\n",
        "    else:\n",
        "        print(f\"\\nüìÇ „É™„Éù„Ç∏„Éà„É™„ÅØÊó¢„Å´Â≠òÂú®„Åó„Åæ„Åô: {REPO_NAME}/\")\n",
        "        print(\"üì• ÊúÄÊñ∞Áâà„Å´Êõ¥Êñ∞‰∏≠...\")\n",
        "        !cd {REPO_NAME} && git pull -q\n",
        "        print(\"‚úÖ Êõ¥Êñ∞ÂÆå‰∫Ü\")\n",
        "\n",
        "    # ‰ΩúÊ•≠„Éá„Ç£„É¨„ÇØ„Éà„É™„ÅÆË®≠ÂÆö\n",
        "    WORK_DIR = Path(REPO_NAME)\n",
        "    os.chdir(WORK_DIR)\n",
        "    print(f\"\\nüìç ‰ΩúÊ•≠„Éá„Ç£„É¨„ÇØ„Éà„É™: {os.getcwd()}\")\n",
        "\n",
        "    # „Éá„Ç£„É¨„ÇØ„Éà„É™ÊßãÈÄ†„ÅÆÁ¢∫Ë™ç\n",
        "    print(\"\\nüìä „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÊßãÈÄ†:\")\n",
        "    !ls -la\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"‚ö†Ô∏è „É≠„Éº„Ç´„É´Áí∞Â¢É„ÅßÂÆüË°å‰∏≠„Åß„Åô\")\n",
        "    if Path.cwd().name == \"notebooks\":\n",
        "        os.chdir(Path.cwd().parent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PZr_6rXsyqlK",
        "outputId": "c7602b0a-ae81-45f8-f609-89ed54dae4fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API„Ç≠„Éº„ÇíSecrets„Åã„ÇâÂèñÂæó„Åó„Åæ„Åó„Åü\n",
            "üîë API„Ç≠„Éº: ********************5tIA\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: OpenAI API„Ç≠„Éº„ÅÆË®≠ÂÆö\n",
        "#@title 2. OpenAI API KeyË®≠ÂÆö { display-mode: \"form\" }\n",
        "#@markdown OpenAI API„Ç≠„Éº„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ„Ç≠„Éº„ÅØÂÆâÂÖ®„Å´ÁÆ°ÁêÜ„Åï„Çå„Åæ„Åô„ÄÇ\n",
        "\n",
        "\n",
        "# API„Ç≠„Éº„ÅÆÂèñÂæóÊñπÊ≥ï„ÇíÈÅ∏Êäû\n",
        "use_secrets = True  #@param {type:\"boolean\"}\n",
        "#@markdown ‚òùÔ∏è Google Colab Secrets„Çí‰ΩøÁî®„Åô„ÇãÂ†¥Âêà„ÅØ„ÉÅ„Çß„ÉÉ„ÇØ\n",
        "\n",
        "if IN_COLAB:\n",
        "    import getpass\n",
        "    from google.colab import userdata\n",
        "    if use_secrets:\n",
        "        try:\n",
        "            # Colab Secrets„Åã„ÇâÂèñÂæó\n",
        "            API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "            print(\"‚úÖ API„Ç≠„Éº„ÇíSecrets„Åã„ÇâÂèñÂæó„Åó„Åæ„Åó„Åü\")\n",
        "        except Exception as e:\n",
        "            print(\"‚ö†Ô∏è Secrets„Åã„Çâ„ÅÆÂèñÂæó„Å´Â§±Êïó„Åó„Åæ„Åó„Åü\")\n",
        "            print(\"Â∑¶ÂÅ¥„ÅÆ„Éë„Éç„É´„ÅÆüîë„Ç¢„Ç§„Ç≥„É≥„Åã„Çâ'OPENAI_API_KEY'„ÇíË®≠ÂÆö„Åó„Å¶„Åè„Å†„Åï„ÅÑ\")\n",
        "            API_KEY = None\n",
        "    else:\n",
        "        # Áõ¥Êé•ÂÖ•Âäõ\n",
        "        api_key_input = getpass.getpass(\"üîë OpenAI API Key„ÇíÂÖ•Âäõ: \")\n",
        "        if api_key_input:\n",
        "            API_KEY = api_key_input\n",
        "            os.environ['OPENAI_API_KEY'] = API_KEY\n",
        "            print(\"‚úÖ API„Ç≠„Éº„ÅåË®≠ÂÆö„Åï„Çå„Åæ„Åó„Åü\")\n",
        "        else:\n",
        "            API_KEY = None\n",
        "            print(\"‚ö†Ô∏è API„Ç≠„Éº„ÅåË®≠ÂÆö„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„ÇìÔºà„Éí„É•„Éº„É™„Çπ„ÉÜ„Ç£„ÉÉ„ÇØÊâãÊ≥ï„ÅÆ„Åø‰ΩøÁî®Ôºâ\")\n",
        "else:\n",
        "    # „É≠„Éº„Ç´„É´Áí∞Â¢É„ÅÆÂ†¥Âêà\n",
        "    API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "    if not API_KEY:\n",
        "        API_KEY = input(\"OpenAI API Key: \")\n",
        "\n",
        "# API„Ç≠„Éº„ÅÆÊ§úË®º\n",
        "if API_KEY:\n",
        "    print(f\"üîë API„Ç≠„Éº: {'*' * 20}{API_KEY[-4:]}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è GPTÊ©üËÉΩ„ÅØ‰ΩøÁî®„Åß„Åç„Åæ„Åõ„Çì\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "71dPwmdnzEfP",
        "outputId": "beb1d973-0b43-48e2-abc4-4bdb56a0a09e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "LA-Bench 2025 Baseline Implementation\n",
            "ÂÆüË°åÁí∞Â¢É: Google Colab\n",
            "ÂÆüË°åÊôÇÂàª: 2025-11-18 06:03:07\n",
            "OpenAIÂà©Áî®ÂèØËÉΩ: True\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: „É©„Ç§„Éñ„É©„É™„ÅÆ„Ç§„É≥„Éù„Éº„Éà„Å®Ë®≠ÂÆö\n",
        "#@title 3. „É©„Ç§„Éñ„É©„É™„ÅÆ„Ç§„É≥„Éù„Éº„Éà { display-mode: \"form\" }\n",
        "\n",
        "import json\n",
        "import yaml\n",
        "import time\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Tuple, Set, Any\n",
        "from pathlib import Path\n",
        "from copy import deepcopy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# „Éá„Éº„ÇøÂá¶ÁêÜ\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "# OpenAI API\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "    OPENAI_AVAILABLE = True\n",
        "except ImportError:\n",
        "    OPENAI_AVAILABLE = False\n",
        "    print(\"‚ö†Ô∏è OpenAI„É©„Ç§„Éñ„É©„É™„ÅåÂà©Áî®„Åß„Åç„Åæ„Åõ„Çì\")\n",
        "\n",
        "# „Éó„É≠„Ç∞„É¨„Çπ„Éê„Éº (ColabÂØæÂøú)\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# „É≠„Ç∞Ë®≠ÂÆö\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%H:%M:%S'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"LA-Bench 2025 Baseline Implementation\")\n",
        "print(f\"ÂÆüË°åÁí∞Â¢É: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
        "print(f\"ÂÆüË°åÊôÇÂàª: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"OpenAIÂà©Áî®ÂèØËÉΩ: {OPENAI_AVAILABLE and API_KEY is not None}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0rypmgB20Yc2"
      },
      "outputs": [],
      "source": [
        "# Cell 4: „Éá„Éº„ÇøÊßãÈÄ†\n",
        "#@title 4. „Éá„Éº„ÇøÊßãÈÄ†„ÅÆÂÆöÁæ© { display-mode: \"form\" }\n",
        "\n",
        "@dataclass\n",
        "class Step:\n",
        "    id: int\n",
        "    text: str\n",
        "\n",
        "@dataclass\n",
        "class ReferenceEntry:\n",
        "    id: int\n",
        "    text: str\n",
        "\n",
        "@dataclass\n",
        "class ExampleInput:\n",
        "    instruction: str\n",
        "    mandatory_objects: Set[str] = field(default_factory=set)\n",
        "    source_protocol_steps: List[Step] = field(default_factory=list)\n",
        "    expected_final_states: Set[str] = field(default_factory=set)\n",
        "    references: List[ReferenceEntry] = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class ExampleOutput:\n",
        "    procedure_steps: List[Step] = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class Measurement:\n",
        "    specific_criteria: Dict[str, int] = field(default_factory=dict)\n",
        "\n",
        "@dataclass\n",
        "class ExampleSample:\n",
        "    id: str\n",
        "    input: ExampleInput\n",
        "    output: ExampleOutput\n",
        "    measurement: Optional[Measurement] = None\n",
        "\n",
        "def _to_set(x):\n",
        "    return set(x) if isinstance(x, (list, set, tuple)) else set()\n",
        "\n",
        "def _to_list(x):\n",
        "    return list(x) if isinstance(x, (list, set, tuple)) else (x if isinstance(x, list) else [])\n",
        "\n",
        "def _to_steps(x) -> List[Step]:\n",
        "    steps: List[Step] = []\n",
        "    arr = _to_list(x)\n",
        "    if not arr:\n",
        "        return steps\n",
        "    if isinstance(arr[0], dict):\n",
        "        for it in arr:\n",
        "            try:\n",
        "                sid = int(it.get(\"id\", len(steps) + 1))\n",
        "            except Exception:\n",
        "                sid = len(steps) + 1\n",
        "            steps.append(Step(id=sid, text=str(it.get(\"text\", \"\")).strip()))\n",
        "    else:\n",
        "        for idx, s in enumerate(arr, start=1):\n",
        "            steps.append(Step(id=idx, text=str(s).strip()))\n",
        "    return steps\n",
        "\n",
        "def _to_references(x) -> List[ReferenceEntry]:\n",
        "    refs: List[ReferenceEntry] = []\n",
        "    arr = _to_list(x)\n",
        "    if not arr:\n",
        "        return refs\n",
        "    if isinstance(arr[0], dict):\n",
        "        for it in arr:\n",
        "            try:\n",
        "                rid = int(it.get(\"id\", len(refs) + 1))\n",
        "            except Exception:\n",
        "                rid = len(refs) + 1\n",
        "            refs.append(ReferenceEntry(id=rid, text=str(it.get(\"text\", \"\")).strip()))\n",
        "    else:\n",
        "        for idx, ref in enumerate(arr, start=1):\n",
        "            refs.append(ReferenceEntry(id=idx, text=str(ref).strip()))\n",
        "    return refs\n",
        "\n",
        "def parse_sample(obj: Dict[str, Any]) -> ExampleSample:\n",
        "    sid = obj.get(\"id\") or obj.get(\"sample_id\") or \"unknown\"\n",
        "    i = obj.get(\"input\", {})\n",
        "    o = obj.get(\"output\", {})\n",
        "    m = obj.get(\"measurement\", {})\n",
        "\n",
        "    # Measurement.specific_criteria „Çí dict „Å´Ê≠£Ë¶èÂåñÔºàlistÂΩ¢Âºè„ÇÇË®±ÂÆπÔºâ\n",
        "    sc_raw = m.get(\"specific_criteria\", {})\n",
        "    sc: Dict[str, int] = {}\n",
        "    if isinstance(sc_raw, dict):\n",
        "        for k, v in sc_raw.items():\n",
        "            try:\n",
        "                sc[str(k)] = int(v)\n",
        "            except Exception:\n",
        "                pass\n",
        "    elif isinstance(sc_raw, list):\n",
        "        for it in sc_raw:\n",
        "            try:\n",
        "                k = it.get(\"item\")\n",
        "                v = int(it.get(\"score\", 0))\n",
        "                if k:\n",
        "                    sc[str(k)] = v\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    sample = ExampleSample(\n",
        "        id=str(sid),\n",
        "        input=ExampleInput(\n",
        "            instruction=str(i.get(\"instruction\", \"\")).strip(),\n",
        "            mandatory_objects=_to_set(i.get(\"mandatory_objects\", [])),\n",
        "            source_protocol_steps=_to_steps(i.get(\"source_protocol_steps\", [])),\n",
        "            expected_final_states=_to_set(i.get(\"expected_final_states\", [])),\n",
        "            references=_to_references(i.get(\"references\", [])),\n",
        "        ),\n",
        "        output=ExampleOutput(\n",
        "            procedure_steps=_to_steps(o.get(\"procedure_steps\", []))\n",
        "        ),\n",
        "        measurement=Measurement(specific_criteria=sc) if sc else None\n",
        "    )\n",
        "    return sample\n",
        "\n",
        "def load_example_jsonl(path: str):\n",
        "    samples = []\n",
        "    p = Path(path)\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f\"JSONL not found: {p}\")\n",
        "    for line in p.read_text(encoding=\"utf-8\").splitlines():\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        try:\n",
        "            obj = json.loads(line)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è JSONL parse error: {e}\")\n",
        "            continue\n",
        "        samples.append(parse_sample(obj))\n",
        "    return samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MXF0Ou0B6sFB",
        "outputId": "4f7a5462-66cf-4b84-a0a8-6010f405a745",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded 5 samples from data/example/example.jsonl\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: JSONL„É≠„Éº„ÉÄ„Éº„ÅÆÂà©Áî®\n",
        "#@title 5. JSONL„Éï„Ç°„Ç§„É´„ÇíË™≠„ÅøËæº„ÇÄ { display-mode: \"form\" }\n",
        "#@markdown example„Çí‰Ωø„ÅÜ„Å®„ÅçÔºö`data/example/example.jsonl`\n",
        "#@markdown public_test„Çí‰Ωø„ÅÜ„Å®„ÅçÔºö`data/public_test/public_test.jsonl`\n",
        "\n",
        "jsonl_path = 'data/example/example.jsonl'  #@param {type:'string'}\n",
        "\n",
        "try:\n",
        "    samples = load_example_jsonl(jsonl_path)\n",
        "    print(f'‚úÖ Loaded {len(samples)} samples from {jsonl_path}')\n",
        "except Exception as e:\n",
        "    print(f'‚ùå Load error: {e}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ94EpzOInJr"
      },
      "outputs": [],
      "source": [
        "# Cell 6: ÂÆüÈ®ìÊâãÈ†Ü„ÅÆÁîüÊàêÔºàOpenAI, PydanticÊßãÈÄ†ÂåñÔºâ\n",
        "#@title 6. LLM„Åß Input „Åã„Çâ OutputÔºàprocedure_stepsÔºâ„ÇíÁîüÊàê { display-mode: \"form\" }\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# „É¢„Éá„É´Ë®≠ÂÆö\n",
        "MODEL_NAME = \"gpt-5-2025-08-07\" #@param [\"gpt-4.1-mini-2025-04-14\", \"gpt-4o-2024-08-06\", \"gpt-5-2025-08-07\", \"gpt-5-mini-2025-08-07\", \"gpt-5-nano-2025-08-07\"]\n",
        "#@markdown gpt-4o-mini, gpt-4o-2024-08-06, „ÅÇ„Çã„ÅÑ„ÅØ„Åù„Çå‰ª•Èôç„ÅÆ„É¢„Éá„É´„Å´ÂØæÂøú„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ<br>\n",
        "#@markdown (Structured output„Çí‰ΩøÁî®„Åó„Å¶„ÅÑ„Çã„Åü„ÇÅ) <br>\n",
        "#@markdown gpt-5Á≥ª„É¢„Éá„É´„Çí‰ΩøÁî®„Åô„ÇãÂ†¥Âêà„ÄÅtemperature=1.0„Å®„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
        "TEMPERATURE = 1 # @param\n",
        "\n",
        "#@markdown `build_messages`Èñ¢Êï∞„Å´„Åä„ÅÑ„Å¶„ÄÅLLM„ÅÆÂÖ•Âäõ„ÇíË®≠Ë®à„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\n",
        "\n",
        "class StepModel(BaseModel):\n",
        "    id: int = Field(ge=1, description=\"„Çπ„ÉÜ„ÉÉ„ÉóÁï™Âè∑\")\n",
        "    text: str = Field(description=\"ÂÆüÈ®ìÊâãÈ†Ü„ÅÆË©≥Á¥∞„Å™Ë™¨Êòé\")\n",
        "\n",
        "class GeneratedOutput(BaseModel):\n",
        "    procedure_steps: List[StepModel] = Field(\n",
        "        description=\"ÂÆüÈ®ìÊâãÈ†Ü„ÅÆ„É™„Çπ„Éà\",\n",
        "        min_items=1,\n",
        "        max_items=50\n",
        "    )\n",
        "\n",
        "def build_messages(sample: ExampleSample) -> list[dict]:\n",
        "    sys = (\n",
        "        \"„ÅÇ„Å™„Åü„ÅØÁîüÂëΩÁßëÂ≠¶ÂÆüÈ®ì„ÅÆÂ∞ÇÈñÄÂÆ∂„Åß„Åô„ÄÇ‰ª•‰∏ã„ÅÆ Input „ÇíË™≠„Åø„ÄÅ\"\n",
        "        \"Êó•Êú¨Ë™û„ÅßÂÆüË°åÂèØËÉΩ„Å™ÂÆüÈ®ìÊâãÈ†ÜÔºàprocedure_stepsÔºâ„ÇíËøî„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\"\n",
        "        \"Âà∂Á¥Ñ: „Çπ„ÉÜ„ÉÉ„ÉóÊï∞„ÅØÊúÄÂ§ß50„ÄÅÂêÑ„Çπ„ÉÜ„ÉÉ„Éó„ÅØ10Êñá‰ª•‰∏ã„ÄÅid„ÅØ1„Åã„ÇâÊòáÈ†Ü„ÄÇ\"\n",
        "    )\n",
        "    user_lines = []\n",
        "    user_lines.append(f\"„ÄêÂÆüÈ®ìÊåáÁ§∫„Äë\\n{sample.input.instruction}\")\n",
        "    if sample.input.mandatory_objects:\n",
        "        user_lines.append(\"\\n„Äê‰ΩøÁî®„Åô„ÇãÁâ©ÂìÅ„Äë\")\n",
        "        for it in sorted(sample.input.mandatory_objects):\n",
        "            user_lines.append(f\"- {it}\")\n",
        "    if sample.input.source_protocol_steps:\n",
        "        user_lines.append(\"\\n„ÄêÂÖÉ„Éó„É≠„Éà„Ç≥„É´„ÅÆÊâãÈ†ÜÔºàÂèÇËÄÉÔºâ„Äë\")\n",
        "        for st in sample.input.source_protocol_steps:\n",
        "            user_lines.append(f\"- {st.id}. {st.text}\")\n",
        "    if sample.input.expected_final_states:\n",
        "        user_lines.append(\"\\n„ÄêÊúüÂæÖ„Åï„Çå„ÇãÊúÄÁµÇÁä∂ÊÖã„Äë\")\n",
        "        for fs in sorted(sample.input.expected_final_states):\n",
        "            user_lines.append(f\"- {fs}\")\n",
        "    if sample.input.references:\n",
        "        user_lines.append(\"\\n„ÄêÂèÇËÄÉÊñáÁåÆ„Äë\")\n",
        "        for ref in sample.input.references:\n",
        "            user_lines.append(f\"- [{ref.id}] {ref.text}\")\n",
        "    usr = \"\\n\".join(user_lines)\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": sys},\n",
        "        {\"role\": \"user\", \"content\": usr},\n",
        "    ]\n",
        "\n",
        "def generate_outputs(samples: list[ExampleSample]) -> list[dict]:\n",
        "    client = OpenAI(api_key=API_KEY)\n",
        "    results: list[dict] = []\n",
        "    for sm in samples:\n",
        "        msgs = build_messages(sm)\n",
        "        try:\n",
        "            completion = client.chat.completions.parse(\n",
        "                model=MODEL_NAME,\n",
        "                messages=msgs,\n",
        "                temperature=TEMPERATURE,\n",
        "                response_format=GeneratedOutput,\n",
        "            )\n",
        "            parsed: GeneratedOutput = completion.choices[0].message.parsed  # type: ignore\n",
        "            steps = [\n",
        "                Step(id=s.id, text=s.text)\n",
        "                for s in sorted(parsed.procedure_steps, key=lambda x: x.id)\n",
        "            ][:50]\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå ÁîüÊàêÂ§±Êïó: {sm.id}: {e}\")\n",
        "            steps = []  # no fallback\n",
        "        results.append({\n",
        "            \"id\": sm.id,\n",
        "            \"procedure_steps\": [{\"id\": s.id, \"text\": s.text} for s in steps],\n",
        "        })\n",
        "    print(f\"‚úÖ ÁîüÊàêÂÆå‰∫Ü: {len(results)} samples\")\n",
        "    return results\n",
        "\n",
        "# ÂÆüË°å\n",
        "generated_results = generate_outputs(samples)\n",
        "if generated_results:\n",
        "    print(f\"‰æã: {generated_results[0]['id']} ‚Üí {len(generated_results[0]['procedure_steps'])} steps\")\n",
        "\n",
        "# ÁîüÊàêÁµêÊûú„Çí JSONL „Åß‰øùÂ≠ò„Åó„ÄÅ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„É™„É≥„ÇØ„ÇíË°®Á§∫\n",
        "ts = time.strftime('%Y%m%d_%H%M%S')\n",
        "out_dir = Path('./outputs/runs')\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "jsonl_path = out_dir / f'generated_{ts}.jsonl'\n",
        "with jsonl_path.open('w', encoding='utf-8') as f:\n",
        "    for rec in generated_results:\n",
        "        obj = {\"id\": rec[\"id\"], \"output\": {\"procedure_steps\": rec[\"procedure_steps\"]}}\n",
        "        line = json.dumps(obj, ensure_ascii=False, separators=(\",\", \":\"))\n",
        "        f.write(line + \"\\n\")\n",
        "print(f\"üìÑ Saved JSONL: {jsonl_path}\")\n",
        "\n",
        "# „ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÔºàColab/„É≠„Éº„Ç´„É´ÂèåÊñπ„Å´ÂØæÂøúÔºâ\n",
        "try:\n",
        "    from google.colab import files as colab_files  # type: ignore\n",
        "    # „ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÁ¢∫Ë™ç„ÉÄ„Ç§„Ç¢„É≠„Ç∞„ÇíÂá∫„Åó„Å¶„ÄÅy„Å™„Çâ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ\n",
        "    from google.colab.output import eval_js\n",
        "    print(f\"Download file: {jsonl_path}\")\n",
        "    confirm = eval_js('confirm(\"ÁîüÊàê„Åï„Çå„ÅüJSONL„Éï„Ç°„Ç§„É´„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Åó„Åæ„Åô„ÅãÔºü\")')\n",
        "    if confirm:\n",
        "      colab_files.download(str(jsonl_path))\n",
        "    else:\n",
        "      print(\"„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Çí„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åó„Åü„ÄÇ\")\n",
        "\n",
        "except Exception:\n",
        "    from IPython.display import FileLink, display\n",
        "    display(FileLink(str(jsonl_path.resolve())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wYtMf3bJOzcN",
        "outputId": "6cce09d1-b8fc-45f9-a2e6-d90ae7c33f6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùå Ë©ï‰æ°Â§±Êïó: sample_1: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-***************************************************************************************************************************************************************************************************************************************************************************************************************************5tIA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
            "‚ùå Ë©ï‰æ°Â§±Êïó: sample_2: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-***************************************************************************************************************************************************************************************************************************************************************************************************************************5tIA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
            "‚ùå Ë©ï‰æ°Â§±Êïó: sample_3: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-***************************************************************************************************************************************************************************************************************************************************************************************************************************5tIA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
            "‚ùå Ë©ï‰æ°Â§±Êïó: sample_4: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-***************************************************************************************************************************************************************************************************************************************************************************************************************************5tIA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
            "‚ùå Ë©ï‰æ°Â§±Êïó: sample_5: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-***************************************************************************************************************************************************************************************************************************************************************************************************************************5tIA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
            "‚úÖ LLM-as-a-judge: Scored 5 samples (0-10)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         id  general_score  specific_score  total_score\n",
              "0  sample_1            0.0             0.0          0.0\n",
              "1  sample_2            0.0             0.0          0.0\n",
              "2  sample_3            0.0             0.0          0.0\n",
              "3  sample_4            0.0             0.0          0.0\n",
              "4  sample_5            0.0             0.0          0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b67d7f6-f37f-42e3-b77a-4969645b079e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>general_score</th>\n",
              "      <th>specific_score</th>\n",
              "      <th>total_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sample_1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sample_2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sample_3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sample_4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sample_5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b67d7f6-f37f-42e3-b77a-4969645b079e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b67d7f6-f37f-42e3-b77a-4969645b079e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b67d7f6-f37f-42e3-b77a-4969645b079e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-db5256c1-0587-4b2c-98a3-7e0d894cf07a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db5256c1-0587-4b2c-98a3-7e0d894cf07a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-db5256c1-0587-4b2c-98a3-7e0d894cf07a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    display(FileLink(str(csv_path\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"sample_2\",\n          \"sample_5\",\n          \"sample_3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"general_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"specific_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ Saved: outputs/runs/eval_llm_20251118_060136.csv\n",
            "Download file: outputs/runs/eval_llm_20251118_060136.csv\n",
            "„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Çí„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åó„Åü„ÄÇ\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: LLM-as-a-judge Ë©ï‰æ°Ôºà10ÁÇπÊ∫ÄÁÇπÔºâ\n",
        "#@title 7. LLM „ÅßÂÖ±ÈÄö5ÁÇπ + ÂÄãÂà•5ÁÇπ„ÇíÊé°ÁÇπ { display-mode: \"form\" }\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"OpenAI SDK v1 „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ`uv add openai` „ÅßËøΩÂä†„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\") from e\n",
        "\n",
        "JUDGE_MODEL = \"gpt-4.1-mini\"  # È´òÊÄßËÉΩÊé®Â•®„É¢„Éá„É´„Å´Â§âÊõ¥ÂèØ\n",
        "JUDGE_TEMPERATURE = 0.2\n",
        "\n",
        "class JudgeOutput(BaseModel):\n",
        "    general_score: float = Field(ge=0, le=5)\n",
        "    specific_score: float = Field(ge=0, le=5)\n",
        "    final_score: float = Field(ge=0, le=10)\n",
        "    general_reason: str\n",
        "    specific_matches: List[str] = []\n",
        "    notes: Optional[str] = None\n",
        "\n",
        "def build_judge_messages(sample: ExampleSample, steps: List[Step]) -> list[dict]:\n",
        "    # Ë©ï‰æ°Âü∫Ê∫ñÔºàÂÖ±ÈÄö5ÁÇπ + ÂÄãÂà•5ÁÇπÔºâ\n",
        "    system = (\n",
        "        \"„ÅÇ„Å™„Åü„ÅØÁîüÂëΩÁßëÂ≠¶ÂÆüÈ®ì„ÅÆÂ∞ÇÈñÄÂÆ∂„Åß„ÅÇ„Çä„ÄÅÂÖ¨Âπ≥„Å™Êé°ÁÇπËÄÖ„Åß„Åô„ÄÇ\"\n",
        "        \"‰ª•‰∏ã„ÅÆÂü∫Ê∫ñ„Å´Âæì„Å£„Å¶„ÄÅ‰∏é„Åà„Çâ„Çå„Åü Input „Å®ÁîüÊàêÊâãÈ†ÜÔºàOutputÔºâ„ÇíË©ï‰æ°„Åó„ÄÅ\"\n",
        "        \"general_score(0-5) „Å® specific_score(0-5) „Å® final_score(0-10) „ÇíÂá∫Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\"\n",
        "        \"\\n\\n[ÂÖ±ÈÄöÊé°ÁÇπÂü∫Ê∫ñ 5ÁÇπÊ∫ÄÁÇπ]\\n\"\n",
        "        \"Âä†ÁÇπ(+1„Åö„Å§): 1) ÂÆüÈ®ìÊåáÁ§∫„ÅÆ„Éë„É©„É°„Éº„ÇøÂèçÊò†, 2) ‰ΩøÁî®„Åô„ÇãÁâ©ÂìÅ„ÅÆÂèçÊò†, 3) ÂÖÉÊâãÈ†Ü„ÅÆË´ñÁêÜÂèçÊò†, 4) ÊúüÂæÖ„Åï„Çå„ÇãÊúÄÁµÇÁä∂ÊÖã„ÅÆÈÅîÊàê, 5) ÈÅ©Âàá„Å™Ë£úÂÆå„ÄÇ\\n\"\n",
        "        \"Ê∏õÁÇπ: ‰∏çËá™ÁÑ∂„Å™Êó•Êú¨Ë™û/„Éè„É´„Ç∑„Éç„Éº„Ç∑„Éß„É≥, Ë®àÁÆó„Éü„Çπ, ÊâãÈ†ÜÁüõÁõæ„ÄÇ\\n\"\n",
        "        \"‰∏äÈôê: ÂÖ•ÂäõÊâãÈ†Ü„ÅÆ‰∏∏ÂÜô„ÅóÁ≠â„ÅÆÈÅéÂ∫¶„ÅÆÂÆâÂÖ®ÊÄß„ÅåË¶ã„Çâ„Çå„ÇãÂ†¥Âêà„ÄÅgeneral_score „ÅØÊúÄÂ§ß2ÁÇπ„Å´Âà∂Èôê„ÄÇ\\n\\n\"\n",
        "        \"[ÂÄãÂà•Êé°ÁÇπÂü∫Ê∫ñ 5ÁÇπÊ∫ÄÁÇπ]\\n\"\n",
        "        \"‰∏é„Åà„Çâ„Çå„Åü specific_criteria „ÅÆÂêÑ item „ÅåÊâãÈ†Ü„Å´Âê´„Åæ„Çå„Çã/Ê∫Ä„Åü„Åô„Å™„Çâ„ÄÅ„Åù„ÅÆ score „ÇíÂä†ÁÇπÔºàÂêàË®à5ÁÇπ„Åß‰∏äÈôêÔºâ„ÄÇ\"\n",
        "    )\n",
        "\n",
        "    parts = []\n",
        "    parts.append(f\"„ÄêÂÆüÈ®ìÊåáÁ§∫„Äë\\n{sample.input.instruction}\")\n",
        "    if sample.input.mandatory_objects:\n",
        "        parts.append(\"\\n„Äê‰ΩøÁî®„Åô„ÇãÁâ©ÂìÅ„Äë\")\n",
        "        for it in sorted(sample.input.mandatory_objects):\n",
        "            parts.append(f\"- {it}\")\n",
        "    if sample.input.source_protocol_steps:\n",
        "        parts.append(\"\\n„ÄêÂÖÉ„Éó„É≠„Éà„Ç≥„É´„ÅÆÊâãÈ†ÜÔºàÂèÇËÄÉÔºâ„Äë\")\n",
        "        for st in sample.input.source_protocol_steps:\n",
        "            parts.append(f\"- {st.id}. {st.text}\")\n",
        "    if sample.input.expected_final_states:\n",
        "        parts.append(\"\\n„ÄêÊúüÂæÖ„Åï„Çå„ÇãÊúÄÁµÇÁä∂ÊÖã„Äë\")\n",
        "        for fs in sorted(sample.input.expected_final_states):\n",
        "            parts.append(f\"- {fs}\")\n",
        "    if sample.input.references:\n",
        "        parts.append(\"\\n„ÄêÂèÇËÄÉÊñáÁåÆ„Äë\")\n",
        "        for ref in sample.input.references:\n",
        "            parts.append(f\"- [{ref.id}] {ref.text}\")\n",
        "\n",
        "    parts.append(\"\\n„ÄêÁîüÊàêÊâãÈ†ÜÔºàOutputÔºâ„Äë\")\n",
        "    for s in steps:\n",
        "        parts.append(f\"- {s.id}. {s.text}\")\n",
        "\n",
        "    parts.append(\"\\n„Äêspecific_criteria„Äë\")\n",
        "    if sample.measurement and sample.measurement.specific_criteria:\n",
        "        for item, sc in sample.measurement.specific_criteria.items():\n",
        "            parts.append(f\"- ({int(sc)}ÁÇπ) {item}\")\n",
        "    else:\n",
        "        parts.append(\"- „Å™„Åó\")\n",
        "\n",
        "    user = \"\\n\".join(parts)\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": user},\n",
        "    ]\n",
        "\n",
        "def judge_with_llm(samples: List[ExampleSample], generated: list[dict]) -> pd.DataFrame:\n",
        "    client = OpenAI(api_key=API_KEY) if 'API_KEY' in globals() and API_KEY else OpenAI()\n",
        "    proc_map = {g['id']: [Step(id=it['id'], text=it['text']) for it in g['procedure_steps']] for g in generated}\n",
        "    rows = []\n",
        "    quota_exhausted = False\n",
        "    def _is_insufficient_quota(err: Exception) -> bool:\n",
        "        s = str(err)\n",
        "        return 'insufficient_quota' in s or 'You exceeded your current quota' in s\n",
        "    for sm in samples:\n",
        "        if quota_exhausted:\n",
        "            print(f\"‚è≠Ô∏è „Çπ„Ç≠„ÉÉ„ÉóÊé°ÁÇπ: {sm.id}Ôºà„ÇØ„Ç©„Éº„Çø‰∏çË∂≥Ôºâ\")\n",
        "            rows.append({\n",
        "                'id': sm.id,\n",
        "                'general_score': 0.0,\n",
        "                'specific_score': 0.0,\n",
        "                'total_score': 0.0,\n",
        "                'notes': 'skipped_due_to_quota',\n",
        "            })\n",
        "            continue\n",
        "        steps = proc_map.get(sm.id, [])\n",
        "        msgs = build_judge_messages(sm, steps)\n",
        "        try:\n",
        "            completion = client.chat.completions.parse(\n",
        "                model=JUDGE_MODEL,\n",
        "                messages=msgs,\n",
        "                temperature=JUDGE_TEMPERATURE,\n",
        "                response_format=JudgeOutput,\n",
        "            )\n",
        "            parsed: JudgeOutput = completion.choices[0].message.parsed  # type: ignore\n",
        "            rows.append({\n",
        "                'id': sm.id,\n",
        "                'general_score': parsed.general_score,\n",
        "                'specific_score': parsed.specific_score,\n",
        "                'total_score': parsed.final_score,\n",
        "                'notes': parsed.notes or '',\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Ë©ï‰æ°Â§±Êïó: {sm.id}: {e}\")\n",
        "            if _is_insufficient_quota(e):\n",
        "                print(\"‚ö†Ô∏è API„ÇØ„Ç©„Éº„Çø‰∏çË∂≥„ÅÆ„Åü„ÇÅ„ÄÅ‰ª•Èôç„ÅÆÊé°ÁÇπ„Çí‰∏≠Êñ≠„Åó„Åæ„Åô„ÄÇ„Éó„É©„É≥/Ë™≤ÈáëË®≠ÂÆö„Çí„ÅîÁ¢∫Ë™ç„Åè„Å†„Åï„ÅÑ„ÄÇ\")\n",
        "                quota_exhausted = True\n",
        "            rows.append({\n",
        "                'id': sm.id,\n",
        "                'general_score': 0.0,\n",
        "                'specific_score': 0.0,\n",
        "                'total_score': 0.0,\n",
        "                'notes': 'evaluation_failed',\n",
        "            })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# ÂÆüË°å\n",
        "df = judge_with_llm(samples, generated_results)\n",
        "print(f\"‚úÖ LLM-as-a-judge: Scored {len(df)} samples (0-10)\")\n",
        "try:\n",
        "    display(df[['id','general_score','specific_score','total_score']])\n",
        "except Exception:\n",
        "    print(df[['id','general_score','specific_score','total_score']])\n",
        "\n",
        "csv_path = out_dir / f'eval_llm_{ts}.csv'\n",
        "df.to_csv(csv_path, index=False, encoding=\"utf_8_sig\")\n",
        "print(f'üìÑ Saved: {csv_path}')\n",
        "\n",
        "try:\n",
        "    # „ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÁ¢∫Ë™ç„ÉÄ„Ç§„Ç¢„É≠„Ç∞„ÇíÂá∫„Åó„Å¶„ÄÅy„Å™„Çâ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ\n",
        "    print(f\"Download file: {csv_path}\")\n",
        "    confirm = eval_js('confirm(\"ÁîüÊàê„Åï„Çå„ÅüCSV„Éï„Ç°„Ç§„É´„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Åó„Åæ„Åô„ÅãÔºü\")')\n",
        "    if confirm:\n",
        "      colab_files.download(str(csv_path))\n",
        "    else:\n",
        "      print(\"„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Çí„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åó„Åü„ÄÇ\")\n",
        "\n",
        "except Exception:\n",
        "    display(FileLink(str(csv_path.resolve())))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "la-bench",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}