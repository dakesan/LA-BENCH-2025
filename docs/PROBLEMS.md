# LA-BenchにおけるGPT-5 One-Shot出力の課題分析レポート

## 1. はじめに

本レポートは、LA-Benchコンペティションで提供された`gpt-5`のone-shot出力結果 (`generated_20251119_082022.jsonl`) を分析し、既存のLLMベースの手法が抱える課題を整理することを目的とします。

分析は、公開テストデータ (`public_test.jsonl`) を正解とし、以下の観点から実施しました。

- **定量的分析**: 生成された手順の数、文の数、文字数などの量的指標を比較。
- **定性的分析**: 手順の詳細度、指示内容の反映、制約の遵守、タスク拒否などの質的側面を評価。

## 2. 分析結果の概要

Pythonスクリプトを用いた自動分析の結果、以下の要約統計が得られました。

| 指標 | GPT-5生成 | 期待値（正解例） |
| :--- | :--- | :--- |
| 平均手順数 | 21.8 | 17.5 |
| 平均文数/手順 | 2.06 | 1.47 |
| 手順数制約違反 (>50) | 0件 | 0件 |
| 文数制約違反 (>10) | 0件 | 0件 |

全体として、GPT-5はコンペティションの基本的な制約（手順数、文数）は遵守できています。しかし、平均手順数や1手順あたりの平均文数が期待値よりも多く、**より詳細で冗長な手順を生成する傾向**が見られます。

## 3. 主要な課題点

詳細な分析から、one-shot LLMによる実験手順生成には、以下の主要な課題が存在することが明らかになりました。

### 課題1：タスクの拒否と過度な安全性

最も深刻な課題として、特定の入力に対して**モデルが手順生成を拒否する**ケースが確認されました。

- **該当サンプル**: `public_test_4`
- **指示内容**: マウス脾臓からのRNA安定化保存
- **GPT-5の応答**: 「申し訳ありませんが、具体的な実験手順の提供はお手伝いできません。」という趣旨の一般的な注意喚起のみを生成。

![手順数比較](https://private-us-east-1.manuscdn.com/sessionFile/Z0MhA5HrFI8nYBDzDTBzBG/sandbox/rHlt5n9DdzsxPHGKpDhUa1-images_1763514381617_na1fn_L2hvbWUvdWJ1bnR1L2FuYWx5c2lzL3Jlc3VsdHMvc3RlcHNfY29tcGFyaXNvbg.png?Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9wcml2YXRlLXVzLWVhc3QtMS5tYW51c2Nkbi5jb20vc2Vzc2lvbkZpbGUvWjBNaEE1SHJGSThuWUJEekRUQnpCRy9zYW5kYm94L3JIbHQ1bjlEZHpzeFBIR0twRGhVYTEtaW1hZ2VzXzE3NjM1MTQzODE2MTdfbmExZm5fTDJodmJXVXZkV0oxYm5SMUwyRnVZV3g1YzJsekwzSmxjM1ZzZEhNdmMzUmxjSE5mWTI5dGNHRnlhWE52YmcucG5nIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNzk4NzYxNjAwfX19XX0_&Key-Pair-Id=K2HSFNDJXOU9YS&Signature=uiCHa1nBVEizflSReK6AZdv0JFKN1C5cr8zYfEC4UVmSvY6kcgk6M6jd7q91jIzc8Vq3TE8HAxd91gGP9l9945CTtYtbzYZN0mlO1cGdXw7VnhknLSs6pN~GP-5w5fNAI8rkS3kQRy2I2Nkwh8wI0UDmPH8L~iwxmdGIrV-wqLKBV0PLMJmKxvSkYvWdetq4X2mCaaO1X1xYho8gypbaFFZxJfwKc5Z8184t4gGSmc5EP-zNjnwbizPg2OQaMddQ3ZEXYbMy0Y5gOegZYNAJ9Pn0ey2nIwqitxNsoHbN3Di6Qzv803gwlAxbJ2pxienEkE79WFnPoCR~QRLZ1sypoA__)
*図1: 期待される手順数とGPT-5生成手順数の比較。public_test_4で生成数が極端に少ないことがわかる。*

このタスクは、他のサンプルと比較して特段危険性が高いわけではありません。しかし、モデルが「組織サンプル」「RNA」といったキーワードから過度に安全性を重視し、具体的な指示の生成を回避したものと考えられます。これは、コンペティションの目的である「実行可能な実験手順の生成」を根本的に達成できない致命的な問題です。

### 課題2：手順の詳細度の不一致

GPT-5の出力は、期待される手順と比較して、詳細度にばらつきが大きい傾向があります。

#### a) 過度な詳細化

多くのサンプルで、GPT-5は期待値よりも多くの手順を生成しています。特に`public_test_3`（カフェイン抽出）では、期待値18ステップに対し34ステップと、約2倍の手順を生成しました。これは、1つの操作を複数のステップに細分化しすぎていることを示唆します。例えば、期待値では1ステップで済む操作を、準備、実行、確認の3ステップに分けるなどです。このような過度な詳細化は、手順を冗長にし、実験者の認知負荷を高める可能性があります。

#### b) 不十分な詳細化

課題1で述べた`public_test_4`のように、タスクを拒否することで、必要な情報が全く提供されないケースも存在します。これは詳細化の極端な失敗例と言えます。

### 課題3：必須物品・パラメータの抜け漏れ

詳細分析の結果、生成された手順の中に、`mandatory_objects`（使用する物品）で指定された物品への言及が欠落しているケースが見られました。

`public_test_4`の拒否応答のケースでは、当然ながら指定された7つの必須物品が一つも言及されていませんでした。他のサンプルにおいても、全ての必須物品が網羅的に手順に組み込まれているとは限らず、重要な機器や試薬が抜け落ちる可能性が示唆されました。

### 課題4：コンテキスト理解と一般化の限界

One-shot設定では、モデルは与えられた単一の例からタスクの意図を推測し、一般化する必要があります。今回の結果は、その能力に限界があることを示しています。

- **過剰な一般化**: `public_test_4`での拒否応答は、過去の学習データに含まれる「医療アドバイスの回避」や「安全でない行為の助長防止」といった一般的な安全原則を、今回の文脈に不適切に適用した結果と考えられます。
- **暗黙知の補完不足**: 期待される出力には、指示に明示されていないが専門家にとっては常識的な手順（例：安全準備、温度管理の確認）が含まれています。GPT-5もある程度はこれを補完しようとしますが、そのレベルは不安定であり、常に適切とは限りません。

### 課題5：評価基準に基づく品質要件の未達成

`public_test.jsonl`の`measurement`フィールドを詳細分析した結果、LA-Benchでは以下の8つの観点で実験手順の品質が評価されることが判明しました。GPT-5のone-shot出力は、これらの要件を十分に満たしていない可能性があります。

#### 評価される8つの品質観点

1. **定量性と具体性** (最重要、全体の76%)
   - 温度、体積、濃度、時間などの数値の明示
   - 許容範囲の具体的指定 (例: `23.0 ± 0.2 °C`)
   - 「適切な量」の定量的定義 (例: `10–100 µL程度`)

2. **手順の具体性** (全体の40%)
   - 操作の順序性の明確化
   - 各ステップの詳細な記述
   - 実行可能なレベルの具体性

3. **実験計画の完全性**
   - 全実験条件の網羅的設定
   - コントロール・ブランクの適切な配置
   - サンプル数の論理的計算

4. **記録と文書化**
   - 実験ノートへの記載義務の明示
   - パラメータの明示的記録
   - 結果報告の形式指定

5. **品質管理・確認プロセス**
   - 測定・確認操作の明示
   - 判定基準の具体化
   - 異常時(気泡発生など)の対応手順

6. **再現性の担保**
   - マスターミックスの使用による誤差低減
   - 標準化された手順
   - トレーサビリティの確保

7. **理論的根拠の理解**
   - 操作の理由・目的の説明
   - 化学的・生物学的根拠の明示
   - 条件設定の論理的説明

8. **安全性への配慮**
   - PPE、ドラフト使用の明記
   - 危険物質の取り扱い手順
   - 廃液処理の適切性

#### スコアリング構造の特徴

- 各エントリは**合計5点**で構成（4〜5個の評価基準）
- **1点項目**(93%): 個別の具体的手順、基本的要件
- **2点項目**(7%): 重要度が高い操作、複数要素を統合した項目、最も厳密な定量管理

#### GPT-5の課題との関連

GPT-5のone-shot出力は、特に以下の点で評価基準を満たしていない可能性が高い：

- **定量性の不足**: 「適量」「適切に」などの曖昧な表現を使い、具体的な数値範囲を明示していない
- **記録・文書化の欠如**: 実験ノートへの記載義務や、記録すべきパラメータの指示が不足
- **理論的根拠の説明不足**: 「なぜその操作が必要か」という理由の説明が省略されがち
- **確認プロセスの省略**: 異常時の対応手順や判定基準が明示されていない
- **再現性への配慮不足**: マスターミックスの使用など、誤差を低減する工夫が欠けている

## 4. 結論と今後の方向性

GPT-5のone-shot出力は、基本的な構文や制約を守る能力は高いものの、以下の深刻な課題を抱えています。

1.  **タスク拒否**: 安全性への過剰配慮から、実行可能なタスクを拒否する場合がある。
2.  **詳細度の不安定性**: 指示によって過度に詳細になったり、逆に情報が欠落したりする。
3.  **指示内容の不完全な反映**: 必須物品などの重要なパラメータを手順に反映しきれない。
4.  **評価基準の未理解**: LA-Benchが求める8つの品質観点（特に定量性、記録、理論的根拠）を満たしていない。

これらの課題は、one-shot学習の限界を示唆しており、コンペティションで高スコアを目指すには、以下のようなアプローチが有効と考えられます。

### 改善アプローチ1: プロンプトエンジニアリング

- **評価基準の明示的組み込み**: プロンプトに8つの品質観点を明記し、特に定量性（数値の明示）、記録・文書化、理論的根拠の説明を強調する
- **Few-shotプロンプティング**: 評価基準を満たす高品質な例を複数提示し、モデルのタスク理解を深める
- **構造化プロンプト**: 各手順に「操作」「数値パラメータ」「理由」「記録事項」「確認基準」を含めるよう指示

### 改善アプローチ2: 多段階生成・検証アプローチ

- **ReAct (Reasoning and Acting) パターン**:
  1. **計画フェーズ**: 実験の全体構成、必要な条件数、コントロール設定を設計
  2. **生成フェーズ**: 計画に基づいて詳細な手順を生成
  3. **検証フェーズ**: 8つの品質観点のチェックリストで自己評価
  4. **修正フェーズ**: 不足している要素（数値、理由、記録指示など）を追加

- **段階的詳細化**:
  1. 手順の骨格を生成
  2. 各手順に定量的パラメータを追加
  3. 理論的根拠と記録事項を追加
  4. 確認・QC手順を追加

### 改善アプローチ3: ハイブリッド・検証システム

- **必須要素チェッカー**:
  - 必須物品の全言及確認
  - 数値パラメータ(温度、体積、濃度、時間)の網羅性確認
  - コントロール・ブランクの設定確認

- **品質スコア予測器**:
  - 生成された手順を8つの観点で自動評価
  - スコアが低い観点について追加生成を促す

- **ドメイン知識ベース統合**:
  - 一般的な実験操作に対する標準パラメータDB
  - 安全性要件のルールベース（PPE、ドラフト使用など）

### 改善アプローチ4: ファインチューニング

- LA-Benchのtrainデータで、評価基準を満たす手順生成に特化したモデルを訓練
- 評価基準をreward modelとした強化学習
- データ拡張: 既存の手順に対して「定量性を追加」「理由を追加」などの変換を適用

### 優先すべき改善項目

評価基準分析の結果、特に以下の要素を強化することが高スコア獲得に直結すると考えられます：

1. **定量性の徹底** (最重要): 全てのパラメータに具体的な数値と範囲を指定
2. **記録・文書化の明示**: 各ステップで何を記録すべきかを明記
3. **理論的根拠の説明**: 主要な操作について「なぜ」を1文で説明
4. **確認・QC手順の追加**: 異常検出の基準と対応方法を明示
5. **再現性への配慮**: マスターミックス使用、誤差低減の工夫を組み込む

特に「タスク拒否」の問題は、プロンプトエンジニアリングだけでは解決が難しい可能性があり、モデルの安全機能とのトレードオフを考慮した、より高度な制御が必要となるでしょう。
