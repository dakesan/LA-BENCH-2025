# LA-BenchにおけるGPT-5 One-Shot出力の課題分析レポート

## 1. はじめに

本レポートは、LA-Benchコンペティションで提供された`gpt-5`のone-shot出力結果 (`generated_20251119_082022.jsonl`) を分析し、既存のLLMベースの手法が抱える課題を整理することを目的とします。

分析は、公開テストデータ (`public_test.jsonl`) を正解とし、以下の観点から実施しました。

- **定量的分析**: 生成された手順の数、文の数、文字数などの量的指標を比較。
- **定性的分析**: 手順の詳細度、指示内容の反映、制約の遵守、タスク拒否などの質的側面を評価。

## 2. 分析結果の概要

Pythonスクリプトを用いた自動分析の結果、以下の要約統計が得られました。

| 指標 | GPT-5生成 | 期待値（正解例） |
| :--- | :--- | :--- |
| 平均手順数 | 21.8 | 17.5 |
| 平均文数/手順 | 2.06 | 1.47 |
| 手順数制約違反 (>50) | 0件 | 0件 |
| 文数制約違反 (>10) | 0件 | 0件 |

全体として、GPT-5はコンペティションの基本的な制約（手順数、文数）は遵守できています。しかし、平均手順数や1手順あたりの平均文数が期待値よりも多く、**より詳細で冗長な手順を生成する傾向**が見られます。

## 3. 主要な課題点

詳細な分析から、one-shot LLMによる実験手順生成には、以下の主要な課題が存在することが明らかになりました。

### 課題1：タスクの拒否と過度な安全性

最も深刻な課題として、特定の入力に対して**モデルが手順生成を拒否する**ケースが確認されました。

- **該当サンプル**: `public_test_4`
- **指示内容**: マウス脾臓からのRNA安定化保存
- **GPT-5の応答**: 「申し訳ありませんが、具体的な実験手順の提供はお手伝いできません。」という趣旨の一般的な注意喚起のみを生成。

![手順数比較](https://private-us-east-1.manuscdn.com/sessionFile/Z0MhA5HrFI8nYBDzDTBzBG/sandbox/rHlt5n9DdzsxPHGKpDhUa1-images_1763514381617_na1fn_L2hvbWUvdWJ1bnR1L2FuYWx5c2lzL3Jlc3VsdHMvc3RlcHNfY29tcGFyaXNvbg.png?Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9wcml2YXRlLXVzLWVhc3QtMS5tYW51c2Nkbi5jb20vc2Vzc2lvbkZpbGUvWjBNaEE1SHJGSThuWUJEekRUQnpCRy9zYW5kYm94L3JIbHQ1bjlEZHpzeFBIR0twRGhVYTEtaW1hZ2VzXzE3NjM1MTQzODE2MTdfbmExZm5fTDJodmJXVXZkV0oxYm5SMUwyRnVZV3g1YzJsekwzSmxjM1ZzZEhNdmMzUmxjSE5mWTI5dGNHRnlhWE52YmcucG5nIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNzk4NzYxNjAwfX19XX0_&Key-Pair-Id=K2HSFNDJXOU9YS&Signature=uiCHa1nBVEizflSReK6AZdv0JFKN1C5cr8zYfEC4UVmSvY6kcgk6M6jd7q91jIzc8Vq3TE8HAxd91gGP9l9945CTtYtbzYZN0mlO1cGdXw7VnhknLSs6pN~GP-5w5fNAI8rkS3kQRy2I2Nkwh8wI0UDmPH8L~iwxmdGIrV-wqLKBV0PLMJmKxvSkYvWdetq4X2mCaaO1X1xYho8gypbaFFZxJfwKc5Z8184t4gGSmc5EP-zNjnwbizPg2OQaMddQ3ZEXYbMy0Y5gOegZYNAJ9Pn0ey2nIwqitxNsoHbN3Di6Qzv803gwlAxbJ2pxienEkE79WFnPoCR~QRLZ1sypoA__)
*図1: 期待される手順数とGPT-5生成手順数の比較。public_test_4で生成数が極端に少ないことがわかる。*

このタスクは、他のサンプルと比較して特段危険性が高いわけではありません。しかし、モデルが「組織サンプル」「RNA」といったキーワードから過度に安全性を重視し、具体的な指示の生成を回避したものと考えられます。これは、コンペティションの目的である「実行可能な実験手順の生成」を根本的に達成できない致命的な問題です。

### 課題2：手順の詳細度の不一致

GPT-5の出力は、期待される手順と比較して、詳細度にばらつきが大きい傾向があります。

#### a) 過度な詳細化

多くのサンプルで、GPT-5は期待値よりも多くの手順を生成しています。特に`public_test_3`（カフェイン抽出）では、期待値18ステップに対し34ステップと、約2倍の手順を生成しました。これは、1つの操作を複数のステップに細分化しすぎていることを示唆します。例えば、期待値では1ステップで済む操作を、準備、実行、確認の3ステップに分けるなどです。このような過度な詳細化は、手順を冗長にし、実験者の認知負荷を高める可能性があります。

#### b) 不十分な詳細化

課題1で述べた`public_test_4`のように、タスクを拒否することで、必要な情報が全く提供されないケースも存在します。これは詳細化の極端な失敗例と言えます。

### 課題3：必須物品・パラメータの抜け漏れ

詳細分析の結果、生成された手順の中に、`mandatory_objects`（使用する物品）で指定された物品への言及が欠落しているケースが見られました。

`public_test_4`の拒否応答のケースでは、当然ながら指定された7つの必須物品が一つも言及されていませんでした。他のサンプルにおいても、全ての必須物品が網羅的に手順に組み込まれているとは限らず、重要な機器や試薬が抜け落ちる可能性が示唆されました。

### 課題4：コンテキスト理解と一般化の限界

One-shot設定では、モデルは与えられた単一の例からタスクの意図を推測し、一般化する必要があります。今回の結果は、その能力に限界があることを示しています。

- **過剰な一般化**: `public_test_4`での拒否応答は、過去の学習データに含まれる「医療アドバイスの回避」や「安全でない行為の助長防止」といった一般的な安全原則を、今回の文脈に不適切に適用した結果と考えられます。
- **暗黙知の補完不足**: 期待される出力には、指示に明示されていないが専門家にとっては常識的な手順（例：安全準備、温度管理の確認）が含まれています。GPT-5もある程度はこれを補完しようとしますが、そのレベルは不安定であり、常に適切とは限りません。

## 4. 結論と今後の方向性

GPT-5のone-shot出力は、基本的な構文や制約を守る能力は高いものの、以下の深刻な課題を抱えています。

1.  **タスク拒否**: 安全性への過剰配慮から、実行可能なタスクを拒否する場合がある。
2.  **詳細度の不安定性**: 指示によって過度に詳細になったり、逆に情報が欠落したりする。
3.  **指示内容の不完全な反映**: 必須物品などの重要なパラメータを手順に反映しきれない。

これらの課題は、one-shot学習の限界を示唆しており、コンペティションで高スコアを目指すには、以下のようなアプローチが有効と考えられます。

- **Few-shotプロンプティング**: より多くの多様な成功例をプロンプトに含めることで、モデルのタスク理解を深め、応答の安定性を向上させる。
- **ファインチューニング**: LA-Benchのデータセット形式に特化したモデルをファインチューニングし、ドメイン知識と出力形式を学習させる。
- **ハイブリッドアプローチ**: LLMの出力を後処理するシステムを構築する。例えば、生成された手順に対して、必須物品やパラメータがすべて含まれているかをチェックし、不足している場合は修正や追加を促すような検証レイヤーを設ける。
- **ReAct (Reasoning and Acting) のようなエージェント的アプローチ**: 手順生成を一度に行うのではなく、「計画」「実行」「検証」のサイクルを回し、自己修正しながら最終的な手順を構築する。

特に「タスク拒否」の問題は、プロンプトエンジニアリングだけでは解決が難しい可能性があり、モデルの安全機能とのトレードオフを考慮した、より高度な制御が必要となるでしょう。
